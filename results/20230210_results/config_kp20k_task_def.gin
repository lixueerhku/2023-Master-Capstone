# Parameters for the metrics


# basic parameters
import metrics.metric
KeyphraseMetric.kp_sep = ';'
KeyphraseMetric.title_sep = '[sep]'
KeyphraseMetric.unk_word = '[unk]'
KeyphraseMetric.invalidate_unk = True


# standard exact matching metrics: f1 and ranking metrics
import metrics.exact_matching_metric
ExactMatchingMetric.k_list = [5, 'M', 'O']


# rouge
import metrics.rouge_metric
RougeMetric.n_list = [1, 2, 'L']


# bert_score
import metrics.bert_score_metric
BertScoreMetric.lang="en"
BertScoreMetric.model_type="bert-base-uncased"
BertScoreMetric.num_layers=8
BertScoreMetric.verbose=False
BertScoreMetric.idf=False
BertScoreMetric.nthreads=8
BertScoreMetric.batch_size=128
BertScoreMetric.rescale_with_baseline=False


# meteor
import metrics.meteor_metric
MeteorMetric.alpha = 0.9
MeteorMetric.beta = 3
MeteorMetric.gamma = 0.5


# semantic matching: p, r, f1, and coverage
import metrics.sem_matching_metric
SemanticMatchingMetric.model_name_or_path='sentence-transformers/all-mpnet-base-v2'
SemanticMatchingMetric.similarity_threshold=0.4
SemanticMatchingMetric.pooling_across_phrases='max'


# retrieval-based scores
import metrics.retrieval_metric
RetrievalMetric.corpus_file='/home/diwu/lm-kpgen/DeepKPG/data/scikp/kp20k/fairseq/train.source'
RetrievalMetric.bi_encoder_name='sentence-transformers/all-mpnet-base-v2'
RetrievalMetric.bi_encoder_corpus_cache_prefix='/local/diwu/kpgeval/cache_for_kpeval/kp20k'
RetrievalMetric.cross_encoder_name='cross-encoder/ms-marco-MiniLM-L-6-v2'
RetrievalMetric.ks=[1, 5, 10]
RetrievalMetric.utility_score_round_limit=5


# moverscore
import metrics.mover_score_metric
MoverScoreMetric.version=1
MoverScoreMetric.n_gram=1
MoverScoreMetric.remove_subwords=False
MoverScoreMetric.remove_stop_words=False
MoverScoreMetric.batch_size=128


# approximate matching (no params required)
import metrics.approx_matching_metric


# diversity
import metrics.diversity_metric
DiversityMetric.ngram=3
DiversityMetric.sent2vec_model='/Users/xueerli/Desktop/capstone/KPEval/wiki_unigrams.bin'
DiversityMetric.sbert_model='sentence-transformers/all-mpnet-base-v2'
DiversityMetric.batch_size=128


# faithfulness 
import metrics.faithfulness_metric
FaithfulnessMetric.nli_model='cross-encoder/nli-roberta-base'
FaithfulnessMetric.nli_label2class={0: 'neutral', 1: 'entailment', 2: 'contradiction'}
FaithfulnessMetric.max_inp_len=400


# bart_score
import metrics.bart_score_metric
BartScoreMetric.model='facebook/bart-large'   # facebook/bart-large, bloomberg/KeyBART
BartScoreMetric.batch_size=4